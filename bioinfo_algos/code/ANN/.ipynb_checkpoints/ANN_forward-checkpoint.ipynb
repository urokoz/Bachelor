{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTK1nItb69_J"
   },
   "source": [
    "# Predicting with Neural Networks\n",
    "\n",
    "### Fill the parts with X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtI1xFfVEhMn"
   },
   "source": [
    "## Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FS1w6JnSoC_P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gebtcRWKgJmw"
   },
   "source": [
    "## Data Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yds3ozYytl8j"
   },
   "source": [
    "### DEFINE THE PATH TO YOUR COURSE DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GhoWNOG7tl8k"
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/mathias/bioinfo_algos/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define run time parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define if we are using blosum or sparse encoding\n",
    "blosum_scheme = False\n",
    "#blosum_scheme = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IhPjK1U6NUNE"
   },
   "source": [
    "### Alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22EsO9nHhUSn"
   },
   "outputs": [],
   "source": [
    "alphabet_file = data_dir + \"Matrices/alphabet\"\n",
    "#alphabet_file = \"https://raw.githubusercontent.com/brunoalvarez89/data/master/algorithms_in_bioinformatics/part_3/alphabet\"\n",
    "alphabet = np.loadtxt(alphabet_file, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6vAARkOhNaIR"
   },
   "source": [
    "### Blosum50 Encoding Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IX7KtVV9Is60"
   },
   "outputs": [],
   "source": [
    "blosum_file = data_dir + \"Matrices/blosum50\"\n",
    "#blosum_file = \"https://raw.githubusercontent.com/brunoalvarez89/data/master/algorithms_in_bioinformatics/part_3/blosum50\"\n",
    "\n",
    "_blosum50 = np.loadtxt(blosum_file, dtype=float).reshape((24, -1)).T\n",
    "\n",
    "blosum50 = {}\n",
    "\n",
    "for i, letter_1 in enumerate(alphabet):\n",
    "    \n",
    "    blosum50[letter_1] = {}\n",
    "\n",
    "    for j, letter_2 in enumerate(alphabet):\n",
    "        \n",
    "        blosum50[letter_1][letter_2] = _blosum50[i, j] / 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Encoding Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_file = data_dir + \"Matrices/sparse\"\n",
    "\n",
    "_sparse = np.loadtxt(sparse_file, dtype=float)\n",
    "sparse = {}\n",
    "\n",
    "for i, letter_1 in enumerate(alphabet):\n",
    "\n",
    "    sparse[letter_1] = {}\n",
    "\n",
    "    for j, letter_2 in enumerate(alphabet):\n",
    "\n",
    "        sparse[letter_1][letter_2] = _sparse[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y3VVxOm7N7e2"
   },
   "source": [
    "## Peptide Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nbDC1pxDN6Zq"
   },
   "outputs": [],
   "source": [
    "def encode(peptides, encoding_scheme, alphabet):\n",
    "    \n",
    "    encoded_peptides = []\n",
    "\n",
    "    for peptide in peptides:\n",
    "\n",
    "        encoded_peptide = []\n",
    "\n",
    "        for peptide_letter in peptide:\n",
    "\n",
    "            for alphabet_letter in alphabet:\n",
    "\n",
    "                encoded_peptide.append(encoding_scheme[peptide_letter][alphabet_letter])\n",
    "        \n",
    "        # add a 1 (bias)\n",
    "        encoded_peptide.append(1)\n",
    "        \n",
    "        # store peptide\n",
    "        encoded_peptides.append(encoded_peptide)\n",
    "        \n",
    "    return np.array(encoded_peptides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fthOCEHqgRNl"
   },
   "source": [
    "## Neural Network Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1Zisf3mgVkZ"
   },
   "source": [
    "### Activation (Sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "D2VuJs8ugaiN"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJfPcRb1gmqr"
   },
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5Pcp8_6JgzfP"
   },
   "outputs": [],
   "source": [
    "def forward(X, w1, w2):\n",
    "    \n",
    "    # X contains the output from each layer, i.e the input values in the first layer\n",
    "    # w1 are weights connecting input to hidden, and w2 weights connecting hidden to output\n",
    "    # In w[i,j]; i is from and j is to\n",
    "   \n",
    "    # get dimension, substracting the bias\n",
    "    input_layer_dim = w1.shape[0] - 1 \n",
    "    hidden_layer_dim = w2.shape[0] - 1\n",
    "    \n",
    "    ################\n",
    "    # hidden layer #\n",
    "    ################\n",
    "    \n",
    "    # activity of hidden layer\n",
    "    # Remember z_j = sum_i w(i,j)*input(i)\n",
    "    for j in range(hidden_layer_dim):\n",
    "        z = 0.0\n",
    "        for i in range(input_layer_dim+1):\n",
    "            z += XXX\n",
    "        X[1][j] = XXX\n",
    "    \n",
    "    ################\n",
    "    # output layer #\n",
    "    ################\n",
    "    \n",
    "    z = 0\n",
    "    for i in range(hidden_layer_dim+1):\n",
    "        z += XXX\n",
    "    X[2][0] = XXX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wvd-bHF07r8y"
   },
   "source": [
    "## Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IWqavwaU7s10"
   },
   "outputs": [],
   "source": [
    "evaluation_file = data_dir + \"ANN/A2403_evaluation\"\n",
    "#evaluation_file = data_dir + \"ANN/A0201_evaluation\"\n",
    "evaluation_data = np.loadtxt(evaluation_file, dtype=str)\n",
    "\n",
    "peptides = evaluation_data[:, 0]\n",
    "if blosum_scheme:\n",
    "    x_eval = encode(peptides, blosum50, alphabet)\n",
    "else:\n",
    "    x_eval = encode(peptides, sparse, alphabet)\n",
    "\n",
    "y_eval = np.array(evaluation_data[:, 1], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYQR6p06Up8h"
   },
   "source": [
    "## Function to load previously saved Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Xu0EqiMLD4xS"
   },
   "outputs": [],
   "source": [
    "def load_network(file_name):\n",
    "\n",
    "    f = open(file_name, \"r\")\n",
    "\n",
    "    n_line = 0\n",
    "\n",
    "    weight_list = []\n",
    "\n",
    "    for line in f:\n",
    "\n",
    "\n",
    "        # clean and separate line\n",
    "        sline = line.strip().split()\n",
    "\n",
    "\n",
    "        # input layer dimension\n",
    "        if n_line == 1:\n",
    "            input_layer_dim = int(sline[0])\n",
    "\n",
    "        # hidden layer dimension    \n",
    "        if n_line == 2:\n",
    "            hidden_layer_dim = int(sline[0])\n",
    "\n",
    "        # output layer dimension\n",
    "        if n_line == 3:\n",
    "            output_layer_dim = int(sline[0])\n",
    "\n",
    "        # model weights\n",
    "        if n_line >= 5:\n",
    "            for i in range(0, len(sline)):\n",
    "                weight_list.append(float(sline[i]))\n",
    "\n",
    "        n_line += 1\n",
    "\n",
    "    # HIDDEN LAYER WEIGHTS\n",
    "    # w_h[i, j] is the weight that links input's feature \"i\" to neuron \"j\" of the hidden layer        \n",
    "    w_h_load = np.zeros(shape=(input_layer_dim+1, hidden_layer_dim))\n",
    "\n",
    "    for i in range(0, (input_layer_dim+1)*hidden_layer_dim, hidden_layer_dim):\n",
    "\n",
    "        for j in range(0, hidden_layer_dim):\n",
    "\n",
    "            row = i // hidden_layer_dim\n",
    "\n",
    "            w_h_load[row, j] = weight_list[i+j]\n",
    "\n",
    "            \n",
    "    # OUTPUT LAYER WEIGHTS\n",
    "    # w_o[i, j] is the weight that links hidden layer's neuron \"i\" to neuron \"j\" of the output layer\n",
    "    w_o_load = np.zeros(shape=(hidden_layer_dim+1, output_layer_dim))\n",
    "\n",
    "    w_h_end = (input_layer_dim+1) * hidden_layer_dim\n",
    "\n",
    "    for i in range(w_h_end, w_h_end+hidden_layer_dim+1, output_layer_dim):\n",
    "\n",
    "        for j in range(0, output_layer_dim):\n",
    "\n",
    "            row = (i - w_h_end) // output_layer_dim\n",
    "            w_o_load[row, j] = weight_list[i+j]\n",
    "            \n",
    "            \n",
    "    # return weight matrices\n",
    "    return w_h_load, w_o_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBGcYUP2MCyS"
   },
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "N0NbseaEoC_e",
    "outputId": "995bd5e1-7e3a-4812-bdb5-aa367df4fe79",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load network\n",
    "synfile_name = data_dir + \"ANN/A2403_sp.syn\"\n",
    "# synfile_name = data_dir + \"ANN/A2403_bl.syn\"\n",
    "# synfile_name = data_dir + \"ANN/A0201_sp.syn\"\n",
    "# synfile_name = data_dir + \"ANN/A0201_bl.syn\"\n",
    "w_h, w_o = load_network(synfile_name)\n",
    "\n",
    "# X matrix \n",
    "input_layer_dim = w_h.shape[0]\n",
    "hidden_layer_dim = w_o.shape[0]\n",
    "output_layer_dim = w_o.shape[1]\n",
    "\n",
    "# Find max network dimensions\n",
    "X_dim = max(input_layer_dim, hidden_layer_dim, output_layer_dim)\n",
    "X = np.zeros(shape=(3, X_dim))\n",
    "\n",
    "# The last column in each X layer is set to 1 to deal with the bias weights\n",
    "X[0][input_layer_dim-1] = 1.0 \n",
    "X[1][hidden_layer_dim-1] = 1.0\n",
    "    \n",
    "# data for plotting\n",
    "y_preds_eval = []\n",
    "\n",
    "# loop\n",
    "for i in range(0, len(x_eval)):        \n",
    "\n",
    "    # fetch training point\n",
    "    x = x_eval[i]\n",
    "    y = y_eval[i]\n",
    "\n",
    "    if len(x) == input_layer_dim:\n",
    "        \n",
    "        X[0] = x\n",
    "\n",
    "        # forward propagation\n",
    "        forward(X, w_h, w_o)\n",
    "        y_pred = XXX\n",
    "        \n",
    "        y_preds_eval.append(y_pred)\n",
    "        \n",
    "        print(peptides[i], y, y_pred)\n",
    "    else:\n",
    "        print(\"Error. Peptide length\", len(x),\"does not match network sizs\", input_layer_dim, \"Skip\")\n",
    "\n",
    "# store training performance\n",
    "eval_perf = pearsonr(y_eval, np.asarray(y_preds_eval))[0]\n",
    "\n",
    "# PERFORMANCE REPORT\n",
    "fig = plt.figure(figsize=(5, 5), dpi = 70)\n",
    "\n",
    "plt.scatter(y_preds_eval, y_eval)\n",
    "plt.ylabel(\"Target Value\", fontsize=10);\n",
    "plt.xlabel(\"Prediction Value\", fontsize=10);\n",
    "\n",
    "# print performance\n",
    "print(\"# Prediction PCC:\", round(eval_perf, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "predict.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
