{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a convolutional neural network to predict MHC ligands\n",
    "The notebook consists of the following sections:\n",
    "\n",
    "0. Module imports, define functions, set constants\n",
    "1. Load Data\n",
    "2. Build Model\n",
    "3. Select Hyper-paramerters\n",
    "4. Compile Model\n",
    "5. Train Model\n",
    "6. Evaluation\n",
    "\n",
    "## Exercise\n",
    "\n",
    "The exercise shows how the general performance is maintained and perhaps even elevated with the use of CNN when we have peptides of different lengths.\n",
    "\n",
    "### Performance evaluation\n",
    "Run the notebook and take a look at how the model performs on data partitioned by peptide length. \n",
    "\n",
    "1. What happens to the overall performance (on peptides of all lengths) compared to FFNN?\n",
    "2. What happens to the performance evaluated only on peptides on length 9? Compare to FFNN again.\n",
    "3. What happens to the performance evaluated on 8-10-11mers (excluding 9mers)? Compare to FFNN again.\n",
    "\n",
    "Can you explain why we would prefer a good performance on 8-9-10-11mers over a higher performance on only 9mers?\n",
    "\n",
    "## ... and you're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff7f3e045f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED=1\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_blosum(filename):\n",
    "    \"\"\"\n",
    "    Read in BLOSUM values into matrix.\n",
    "    \"\"\"\n",
    "    aa = ['A', 'R', 'N' ,'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', 'X']\n",
    "    df = pd.read_csv(filename, sep='\\s+', comment='#', index_col=0)\n",
    "    return df.loc[aa, aa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_peptide_target(filename):\n",
    "    \"\"\"\n",
    "    Read amino acid sequence of peptides and\n",
    "    corresponding log transformed IC50 binding values from text file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename, sep='\\s+', usecols=[0,1], names=['peptide','target'])\n",
    "    return df[df.peptide.apply(len) <= MAX_PEP_SEQ_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_peptides(Xin):\n",
    "    \"\"\"\n",
    "    Encode AA seq of peptides using BLOSUM50.\n",
    "    Returns a tensor of encoded peptides of shape (batch_size, MAX_PEP_SEQ_LEN, n_features)\n",
    "    \"\"\"\n",
    "    blosum = load_blosum(blosum_file)\n",
    "    \n",
    "    batch_size = len(Xin)\n",
    "    n_features = len(blosum)\n",
    "    \n",
    "    Xout = np.zeros((batch_size, MAX_PEP_SEQ_LEN, n_features), dtype=np.int8) # should it be uint? is there a purpose to that?\n",
    "    \n",
    "    for peptide_index, row in Xin.iterrows():\n",
    "        for aa_index in range(len(row.peptide)):\n",
    "            Xout[peptide_index, aa_index] = blosum[ row.peptide[aa_index] ].values\n",
    "            \n",
    "    return Xout, Xin.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke(early_stopping, loss, model, implement=False):\n",
    "    if implement == False:\n",
    "        return False\n",
    "    else:\n",
    "        early_stopping(loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target_values(data):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    for partition, label in data:\n",
    "        x = partition.index\n",
    "        y = partition.target\n",
    "        plt.scatter(x, y, label=label, marker='.')\n",
    "    plt.axhline(y=BINDER_THRESHOLD, color='r', linestyle='--', label='Binder threshold')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.title('Target values')\n",
    "    plt.xlabel('Index of dependent variable')\n",
    "    plt.ylabel('Dependent varible')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PEP_SEQ_LEN = 11\n",
    "BINDER_THRESHOLD = 0.426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLELE = 'A0301'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "blosum_file = \"../data/BLOSUM50\"\n",
    "train_data = \"../data/%s/train_BA\" % ALLELE\n",
    "valid_data = \"../data/%s/valid_BA\" % ALLELE\n",
    "test_data = \"../data/%s/test_BA\" % ALLELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = load_peptide_target(train_data)\n",
    "valid_raw = load_peptide_target(valid_data)\n",
    "test_raw = load_peptide_target(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_, y_train_ = encode_peptides(train_raw)\n",
    "x_valid_, y_valid_ = encode_peptides(valid_raw)\n",
    "x_test_, y_test_ = encode_peptides(test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data dimensions for the train set and validation set (batch_size, MAX_PEP_SEQ_LEN, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3951, 11, 21)\n",
      "(1329, 11, 21)\n",
      "(1321, 11, 21)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_.shape)\n",
    "print(x_valid_.shape)\n",
    "print(x_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = x_train_.shape[0]\n",
    "n_features = x_train_.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Variable(torch.from_numpy(x_train_.astype('float32')))\n",
    "y_train = Variable(torch.from_numpy(y_train_.astype('float32'))).view(-1, 1)\n",
    "x_valid = Variable(torch.from_numpy(x_valid_.astype('float32')))\n",
    "y_valid = Variable(torch.from_numpy(y_valid_.astype('float32'))).view(-1, 1)\n",
    "x_test = Variable(torch.from_numpy(x_test_.astype('float32')))\n",
    "y_test = Variable(torch.from_numpy(y_test_.astype('float32'))).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNpep(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_filters, k, n_l1):\n",
    "        super(CNNpep, self).__init__()\n",
    "        self.conv_layer = nn.Conv1d(in_channels=21, \n",
    "                                    out_channels=n_filters,\n",
    "                                    kernel_size=k, \n",
    "                                    stride=1,\n",
    "                                    padding=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(n_filters, n_l1)\n",
    "        self.fc2 = nn.Linear(n_l1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Permutation of the dimensions for the cnn\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.conv_layer(x))\n",
    "        x, _ = torch.max(x, axis=2)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "    https://pytorch.org/docs/master/nn.init.html\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0) # alternative command: m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3000\n",
    "MINI_BATCH_SIZE = 512\n",
    "N_HIDDEN_NEURONS = 16\n",
    "LEARNING_RATE = 0.1\n",
    "PATIENCE = EPOCHS // 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNNpep(n_filters=100, k=3, n_l1=16)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    train_loss, valid_loss = [], []\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=PATIENCE)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        net.train()\n",
    "        pred = net(x_train)\n",
    "        loss = criterion(pred, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.data)\n",
    "\n",
    "        net.eval()\n",
    "        pred = net(x_valid)\n",
    "        loss = criterion(pred, y_valid)  \n",
    "        valid_loss.append(loss.data)\n",
    "        \n",
    "        if epoch % (EPOCHS//10) == 0:\n",
    "            print('Train Epoch: {}\\tLoss: {:.6f}\\tVal Loss: {:.6f}'.format(epoch, train_loss[-1], valid_loss[-1]))\n",
    "\n",
    "        if invoke(early_stopping, valid_loss[-1], net, implement=True):\n",
    "            net.load_state_dict(torch.load('checkpoint.pt'))\n",
    "            break\n",
    "            \n",
    "    return net, train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\tLoss: 0.070979\tVal Loss: 0.072850\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 2 out of 300\n",
      "EarlyStopping counter: 3 out of 300\n",
      "EarlyStopping counter: 4 out of 300\n",
      "EarlyStopping counter: 5 out of 300\n",
      "EarlyStopping counter: 6 out of 300\n",
      "EarlyStopping counter: 7 out of 300\n",
      "EarlyStopping counter: 8 out of 300\n",
      "EarlyStopping counter: 9 out of 300\n",
      "EarlyStopping counter: 10 out of 300\n",
      "EarlyStopping counter: 11 out of 300\n",
      "EarlyStopping counter: 12 out of 300\n",
      "EarlyStopping counter: 13 out of 300\n",
      "EarlyStopping counter: 14 out of 300\n",
      "EarlyStopping counter: 15 out of 300\n",
      "Train Epoch: 300\tLoss: 0.049481\tVal Loss: 0.052036\n",
      "EarlyStopping counter: 16 out of 300\n",
      "EarlyStopping counter: 17 out of 300\n",
      "EarlyStopping counter: 18 out of 300\n",
      "EarlyStopping counter: 19 out of 300\n",
      "EarlyStopping counter: 20 out of 300\n",
      "EarlyStopping counter: 21 out of 300\n",
      "EarlyStopping counter: 22 out of 300\n",
      "EarlyStopping counter: 23 out of 300\n",
      "EarlyStopping counter: 24 out of 300\n",
      "EarlyStopping counter: 25 out of 300\n",
      "EarlyStopping counter: 26 out of 300\n",
      "EarlyStopping counter: 27 out of 300\n",
      "EarlyStopping counter: 28 out of 300\n",
      "EarlyStopping counter: 29 out of 300\n",
      "EarlyStopping counter: 30 out of 300\n",
      "EarlyStopping counter: 31 out of 300\n",
      "EarlyStopping counter: 32 out of 300\n",
      "EarlyStopping counter: 33 out of 300\n",
      "EarlyStopping counter: 34 out of 300\n",
      "EarlyStopping counter: 35 out of 300\n",
      "EarlyStopping counter: 36 out of 300\n",
      "EarlyStopping counter: 37 out of 300\n",
      "EarlyStopping counter: 38 out of 300\n",
      "EarlyStopping counter: 39 out of 300\n",
      "EarlyStopping counter: 40 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "Train Epoch: 600\tLoss: 0.037598\tVal Loss: 0.039901\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n",
      "EarlyStopping counter: 1 out of 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 300\n"
     ]
    }
   ],
   "source": [
    "net, train_loss, valid_loss = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(burn_in=20):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.plot(list(range(burn_in, len(train_loss))), train_loss[burn_in:], label='Training loss')\n",
    "    plt.plot(list(range(burn_in, len(valid_loss))), valid_loss[burn_in:], label='Validation loss')\n",
    "\n",
    "    # find position of lowest validation loss\n",
    "    minposs = valid_loss.index(min(valid_loss))+1 \n",
    "    plt.axvline(minposs, linestyle='--', color='r',label='Minimum Validation Loss')\n",
    "\n",
    "    plt.legend(frameon=False)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "pred = net(x_test)\n",
    "loss = criterion(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_target_values(data=[(pd.DataFrame(pred.data.numpy(), columns=['target']), 'Prediction'),\n",
    "                         (test_raw, 'Target')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform targets to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class = np.where(y_test.flatten() >= BINDER_THRESHOLD, 1, 0)\n",
    "y_pred_class = np.where(pred.flatten() >= BINDER_THRESHOLD, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Caracteristic (ROC) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(peptide_length=[9]):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, label = 'AUC = %0.2f (%smer)' %(roc_auc, '-'.join([str(i) for i in peptide_length])))\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1], c='black', linestyle='--')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining targets and prediction values with peptide length in a dataframe\n",
    "pred_per_len = pd.DataFrame([test_raw.peptide.str.len().to_list(),\n",
    "                             y_test_class,\n",
    "                             pred.flatten().detach().numpy()],\n",
    "                            index=['peptide_length','target','prediction']).T\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "# For each peptide length compute AUC and plot ROC\n",
    "for length, grp in pred_per_len.groupby('peptide_length'):\n",
    "    fpr, tpr, threshold = roc_curve(grp.target, grp.prediction)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plot_roc_curve(peptide_length=[int(length)])\n",
    "\n",
    "# Evaluating model on peptides of length other than 9 AA.\n",
    "for lengths in [[8,10,11],[8,9,10,11]]:\n",
    "    grp = pred_per_len[pred_per_len.peptide_length.isin(lengths)]\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(grp.target, grp.prediction)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plot_roc_curve(peptide_length=lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matthew's Correlation Coefficient (MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mcc():\n",
    "    plt.title('Matthews Correlation Coefficient')\n",
    "    plt.scatter(y_test.flatten().detach().numpy(), pred.flatten().detach().numpy(), label = 'MCC = %0.2f' % mcc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.xlabel('Validation targets')\n",
    "    plt.show()\n",
    "\n",
    "plot_mcc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
